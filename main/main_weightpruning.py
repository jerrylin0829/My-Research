"""
WeightPruning éºå¿˜å¯¦é©—ä¸»ç¨‹å¼
"""
import os
import sys
import time
import json
import argparse
import logging
import torch
import torch.nn as nn
import shutil
import numpy as np
from datetime import datetime
import pandas as pd
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.vit_LSA_classattn import VisionTransformer
from methods.weight_pruning_unlearner import WeightPruningUnlearner
from mul_vit_1 import MembershipInferenceAttack, MachineUnlearning
from utils.evaluation_utils import (
    enhanced_unlearning_evaluation, 
    print_enhanced_evaluation_report,
    calculate_model_size_difference,
)
from utils.storage_utils import ExperimentStorage
from mia_visualization import visualize_mia_features

def setup_logging(log_file):
    """è¨­ç½®æ—¥èªŒç³»çµ±"""
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ],
        force=True
    )
    return logging.getLogger(__name__)


class WeightPruningExperiment:
    """WeightPruning éºå¿˜å¯¦é©—ç®¡ç†å™¨ - ä½¿ç”¨çµ±ä¸€çš„Storageç³»çµ±"""
    
    def __init__(self, args):
        self.args = args
        self.base_model_path = args.model_path
        self.device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
        
        # ä½¿ç”¨çµ±ä¸€çš„å„²å­˜ç³»çµ±
        self.storage = ExperimentStorage(args.output_dir)
        
        # å‰µå»ºå®Œæ•´å¯¦é©—çµæ§‹
        self.exp_dir, self.exp_name = self.storage.create_complete_experiment_structure("weightpruning")
        
        # è¨­ç½®æ—¥èªŒç³»çµ±
        self.logger, self.log_file = self.storage.setup_logging_system(self.exp_dir, self.exp_name)
        
        # è¨­ç½®TensorBoard
        self.tensorboard_dir, self.main_writer = self.storage.setup_tensorboard(self.exp_dir)
        
        self.batch_size = args.batch_size
        self.num_workers = args.num_workers
        self.fine_tune_epochs = args.unlearn_epochs
        
        # é»ƒé‡‘æ¨™æº–åƒæ•¸
        self.gs_epochs = args.gs_epochs
        self.gs_lr = args.gs_lr
        self.gs_scheduler = args.gs_scheduler
        self.gs_min_lr = args.gs_min_lr
        self.gs_weight_decay = args.gs_weight_decay
        self.use_mixup = args.use_mixup
        self.use_cutmix = args.use_cutmix
        self.mix_alpha = args.mix_alpha
        self.use_logit_penalty = args.use_logit_penalty
        self.use_forget_uniform = args.use_forget_uniform
        self.use_forget_distill = args.use_forget_distill

        self.prune_ratios = args.prune_ratios

        def _parse_target_layers(s):
            return [t.strip() for t in s.split(',') if t.strip()]
        
        self.prune_target_layers = _parse_target_layers(args.prune_target_layers)

        # è©•ä¼°åƒæ•¸
        # self.run_mia = args.run_mia
        # self.mia_epochs = args.mia_epochs
        self.run_mia = False  # ğŸ”§ æš«æ™‚ç¦ç”¨ MIA
        self.mia_epochs = 0
        self.run_enhanced_eval = args.run_enhanced_eval
        
        # MIA é¡å¤–åƒæ•¸ï¼ˆå¦‚æœè…³æœ¬éœ€è¦ï¼‰
        # self.mia_lr = getattr(args, 'mia_lr', 1e-3)
        # self.mia_use_scheduler = getattr(args, 'mia_use_scheduler', True)
        self.mia_lr = 1e-3
        self.mia_use_scheduler = True
        
        # æ¨¡å‹åƒæ•¸
        self.model_args = {
            'img_size': 32,
            'patch_size': 4,
            'in_chans': 3,
            'num_classes': 100,
            'embed_dim': 300,
            'depth': 10,
            'num_heads': 12,
            'mlp_ratio': 4.0,
            'qkv_bias': True,
            'drop_rate': 0.0,
            'attn_drop_rate': 0.0,
            'drop_path_rate': 0.05,
            'is_LSA': True
        }
        
        # ä¿å­˜å®Œæ•´é…ç½®ä¸¦è¨˜éŒ„å¯¦é©—é–‹å§‹
        config_file, self.config = self.storage.save_complete_experiment_config(
            self.exp_dir, "WeightPruning", args, self.model_args
        )
        
        # çµ±ä¸€çš„å¯¦é©—é–‹å§‹æ—¥èªŒ
        self.storage.log_experiment_start(
            self.logger, "WeightPruning", self.exp_name, self.exp_dir, self.config, args
        )
        
        # æ–°å¢ GS (Retrain model) çš„å¿«å–ï¼Œé¿å…é‡è¤‡è¨“ç·´
        self.gs_cache = {}

        self.logger.info(f"TensorBoard: tensorboard --logdir={self.tensorboard_dir}")
        print(f"ğŸš€ WeightPruningå¯¦é©—é–‹å§‹ - ç›®éŒ„: {self.exp_dir}")

    def _prepare_gold_standard(self, forget_classes, forget_key):
        """å°ˆé–€è¨“ç·´ã€è©•ä¼°ä¸¦ä¿å­˜ä¸€å€‹é»ƒé‡‘æ¨™æº–æ¨¡å‹"""
        self.logger.info(f"===== é–‹å§‹æº–å‚™ {forget_key} çš„é»ƒé‡‘æ¨™æº–æ¨¡å‹ =====")
        
        # å»ºç«‹ä¸€å€‹æš«æ™‚çš„ MachineUnlearning å¯¦ä¾‹ä¾†åŸ·è¡Œè¨“ç·´
        temp_output_dir = f"./temp_gs_training_{forget_key}"
        mul = MachineUnlearning(
            model_class=VisionTransformer,
            model_args=self.model_args,
            device=self.device,
            output_dir=temp_output_dir,
            args=self.args
        )
        
        mul.prepare_data(dataset_name='CIFAR100', forget_classes=forget_classes)
        
        # è¨“ç·´ GS æ¨¡å‹
        mul.train_gold_standard(
            epochs=self.gs_epochs,
            lr=self.gs_lr,
            lr_scheduler_type=self.gs_scheduler,
            min_lr=self.gs_min_lr,
            weight_decay=self.gs_weight_decay,
            use_mixup=self.use_mixup,
            use_cutmix=self.use_cutmix,
            mix_alpha=self.mix_alpha,
            use_logit_penalty=self.use_logit_penalty
        )
        
        # è©•ä¼° GS æ¨¡å‹
        gs_retain_acc = mul._evaluate_retain(mul.retrained_model)
        gs_forget_acc = mul._evaluate_forget(mul.retrained_model)
        
        # å®šç¾©å„²å­˜è·¯å¾‘ä¸¦ä¿å­˜æ¨¡å‹
        gs_model_path = os.path.join(self.exp_dir, "models", f"gs_model_{forget_key}.pth")
        torch.save(mul.retrained_model.state_dict(), gs_model_path)
        self.logger.info(f"é»ƒé‡‘æ¨™æº–æ¨¡å‹å·²ä¿å­˜è‡³: {gs_model_path}")

        # æ¸…ç†æš«å­˜ç›®éŒ„
        shutil.rmtree(temp_output_dir, ignore_errors=True)

        # è¿”å›åŒ…å«è·¯å¾‘å’ŒæŒ‡æ¨™çš„å­—å…¸
        return {
            "model_path": gs_model_path,
            "retrained_model_obj": mul.retrained_model, # è¿”å›æ¨¡å‹ç‰©ä»¶ä»¥ä¾›å¾ŒçºŒä½¿ç”¨
            "metrics": {
                "gs_retain_acc": gs_retain_acc,
                "gs_forget_acc": gs_forget_acc
            },
            "retraining_time": mul.results.get('retraining_time', 0)
        }
    
    def run_all_experiments(self, forget_class_counts, selected_strategies=None):
        """æ‰¹é‡åŸ·è¡Œæ‰€æœ‰å¯¦é©—çµ„åˆï¼ˆé«˜æ•ˆç‰ˆï¼‰"""
        # === éšæ®µä¸€ï¼šé å…ˆè¨ˆç®—ä¸¦å¿«å–æ‰€æœ‰é»ƒé‡‘æ¨™æº–æ¨¡å‹ ===
        self.logger.info("="*80)
        self.logger.info("éšæ®µä¸€ï¼šé–‹å§‹æº–å‚™æ‰€æœ‰é»ƒé‡‘æ¨™æº–æ¨¡å‹...")
        self.logger.info("="*80)
        
        import random
        for forget_count in forget_class_counts:
            forget_key = f"forget{forget_count}"
            if forget_key not in self.gs_cache:
                # ç‚ºäº†å¯é‡ç¾æ€§ï¼Œå›ºå®šéš¨æ©Ÿç¨®å­ä¾†ç”Ÿæˆéºå¿˜é¡åˆ¥
                random.seed(42 + forget_count)
                forget_classes = set(random.sample(range(100), forget_count))
                
                gs_info = self._prepare_gold_standard(forget_classes, forget_key)
                self.gs_cache[forget_key] = gs_info
                # æˆ‘å€‘éœ€è¦ forget_classes æœ¬èº«ä»¥ä¾›å¾ŒçºŒä½¿ç”¨
                self.gs_cache[forget_key]['forget_classes'] = forget_classes
        
        self.logger.info("âœ… æ‰€æœ‰é»ƒé‡‘æ¨™æº–æ¨¡å‹æº–å‚™å®Œç•¢ï¼")

        # === éšæ®µäºŒï¼šåŸ·è¡Œæ‰€æœ‰éºå¿˜ç­–ç•¥ ===
        self.logger.info("="*80)
        self.logger.info("éšæ®µäºŒï¼šé–‹å§‹åŸ·è¡Œæ‰€æœ‰éºå¿˜ç­–ç•¥...")
        self.logger.info("="*80)

        # ç²å–ç­–ç•¥é…ç½®
        temp_unlearner = WeightPruningUnlearner(None, self.device)
        all_strategies = temp_unlearner.get_strategy_configs(prune_ratios=self.prune_ratios, 
                                                             target_layers=self.prune_target_layers)
        
        # ç¯©é¸ç­–ç•¥ (é‚è¼¯ä¸è®Š)
        if selected_strategies is None or 'all' in selected_strategies:
            strategies = all_strategies
        else:
            strategies = {name: config for name, config in all_strategies.items()
                         if any(strat in name for strat in selected_strategies)}
        
        all_results = {}
        total_experiments = len(forget_class_counts) * len(strategies)
        experiment_step = 0

        with tqdm(total=total_experiments, desc="æ‰¹é‡å¯¦é©—é€²åº¦") as pbar:
            for forget_count in forget_class_counts:
                forget_key = f"forget{forget_count}"
                all_results[forget_key] = {}
                
                # å¾å¿«å–ä¸­ç²å– GS è³‡è¨Šå’Œéºå¿˜é¡åˆ¥
                gs_info = self.gs_cache[forget_key]
                forget_classes = gs_info['forget_classes']
                
                for strategy_name, strategy_config in strategies.items():
                    experiment_step += 1
                    try:
                        pbar.set_description(f"åŸ·è¡Œ {forget_key}_{strategy_name}")
                        
                        # åŸ·è¡Œå–®ä¸€éºå¿˜å¯¦é©—ï¼Œå‚³å…¥å·²æº–å‚™å¥½çš„ GS è³‡è¨Š
                        result = self.run_experiment(forget_classes, strategy_name, strategy_config, gs_info, global_step=experiment_step)
                        
                        all_results[forget_key][strategy_name] = result
                        
                        self._write_tensorboard_summary(forget_key, strategy_name, result, experiment_step)
                        
                    except Exception as e:
                        error_msg = str(e)
                        all_results[forget_key][strategy_name] = {'error': error_msg}
                        self.logger.error(f"âŒ å¤±æ•—: {forget_key} - {strategy_name}: {error_msg}", exc_info=True)
                    
                    pbar.update(1)
        
        # ç”¢ç”Ÿå ±å‘Š
        self._generate_comprehensive_csv(all_results)
        self._generate_detailed_report(all_results)
        self._perform_statistical_analysis(all_results)
        
        self.main_writer.close()
        self.logger.info("ğŸ‰ WeightPruningå¯¦é©—å…¨éƒ¨å®Œæˆï¼")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.exp_dir}")
        return self.exp_dir, all_results

    def _write_tensorboard_summary(self, forget_key, strategy_name, result, step):
        """å¯«å…¥ TensorBoard æ‘˜è¦"""
        if 'error' in result:
            return
            
        prefix = f"{forget_key}_{strategy_name}"
        
        # åŸºç¤æŒ‡æ¨™
        perf = result.get('performance_metrics', {})
        self.main_writer.add_scalar(f"{prefix}/Original_Retain_Acc", perf.get('original_retain_acc', 0), step)
        self.main_writer.add_scalar(f"{prefix}/Unlearned_Retain_Acc", perf.get('unlearned_retain_acc', 0), step)
        self.main_writer.add_scalar(f"{prefix}/GS_Retain_Acc", perf.get('gs_retain_acc', 0), step)
        
        # éºå¿˜æŒ‡æ¨™
        unlearn = result.get('unlearning_metrics', {})
        self.main_writer.add_scalar(f"{prefix}/ZRF_Score", unlearn.get('zrf_score', 0), step)
        self.main_writer.add_scalar(f"{prefix}/Forget_Effectiveness", unlearn.get('forget_effectiveness', 0), step)
        self.main_writer.add_scalar(f"{prefix}/Retain_Preservation", unlearn.get('retain_preservation', 0), step)
        
        # æ™‚é–“
        timing = result.get('timing', {})
        self.main_writer.add_scalar(f"{prefix}/Unlearning_Time", timing.get('unlearning_time', 0), step)
        
        self.main_writer.flush()

    def _generate_comprehensive_csv(self, all_results):
        """ç”Ÿæˆè©³ç´° CSV æ¯”è¼ƒè¡¨"""
        rows = []
        
        for forget_key, strategies_results in all_results.items():
            for strategy_name, result in strategies_results.items():
                if 'error' in result:
                    continue
                    
                perf = result.get('performance_metrics', {})
                unlearn = result.get('unlearning_metrics', {})
                timing = result.get('timing', {})
                model_analysis = result.get('model_analysis', {})
                enhanced = result.get('enhanced_metrics', {})
                mia = result.get('mia_results', {})
                
                row = {
                    'Forget_Classes': forget_key,
                    'Strategy': strategy_name,
                    'Original_Retain_Acc': perf.get('original_retain_acc', 0),
                    'Original_Forget_Acc': perf.get('original_forget_acc', 0),
                    'Unlearned_Retain_Acc': perf.get('unlearned_retain_acc', 0),
                    'Unlearned_Forget_Acc': perf.get('unlearned_forget_acc', 0),
                    'GS_Retain_Acc': perf.get('gs_retain_acc', 0),
                    'GS_Forget_Acc': perf.get('gs_forget_acc', 0),
                    'ZRF_Score': unlearn.get('zrf_score', 0),
                    'KL_Divergence': unlearn.get('kl_divergence', 0),
                    'Forget_Effectiveness': unlearn.get('forget_effectiveness', 0),
                    'Retain_Preservation': unlearn.get('retain_preservation', 0),
                    'Unlearning_Time': timing.get('unlearning_time', 0),
                    'Retraining_Time': timing.get('retraining_time', 0),
                    'Sparsity_Increase': model_analysis.get('sparsity_increase', 0),
                    'Compression_Ratio': model_analysis.get('compression_ratio', 1),
                    'Cosine_Similarity': enhanced.get('cosine_similarity', 0),
                    # 'MIA_Accuracy': mia.get('accuracy', 0.5)  # ğŸ”§ MIA æš«æ™‚ç¦ç”¨
                    'MIA_Accuracy': 0.5  # é è¨­å€¼
                }
                rows.append(row)
        
        if rows:
            df = pd.DataFrame(rows)
            csv_path = f"{self.exp_dir}/results/comprehensive_comparison.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8')
            self.logger.info(f"CSV æ¯”è¼ƒè¡¨å·²ä¿å­˜: {csv_path}")
            return csv_path

    def _generate_detailed_report(self, all_results):
        """ç”Ÿæˆè©³ç´°æ–‡å­—å ±å‘Š"""
        report_path = f"{self.exp_dir}/results/detailed_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("WeightPruning éºå¿˜å¯¦é©—è©³ç´°å ±å‘Š\n")
            f.write("="*50 + "\n\n")
            f.write(f"å¯¦é©—æ™‚é–“: {datetime.now()}\n")
            f.write(f"å¯¦é©—ç›®éŒ„: {self.exp_dir}\n\n")
            
            # å¯¦é©—æ¦‚è¦½
            total_experiments = sum(len(strategies) for strategies in all_results.values())
            successful = sum(1 for strategies in all_results.values() 
                           for result in strategies.values() if 'error' not in result)
            
            f.write(f"å¯¦é©—ç¸½æ•¸: {total_experiments}\n")
            f.write(f"æˆåŠŸå¯¦é©—: {successful}\n")
            f.write(f"æˆåŠŸç‡: {successful/total_experiments*100:.1f}%\n\n")
            
            # å„å¯¦é©—çµæœ
            for forget_key, strategies_results in all_results.items():
                f.write(f"\n{forget_key.upper()} çµæœ:\n")
                f.write("-" * 30 + "\n")
                
                for strategy_name, result in strategies_results.items():
                    if 'error' in result:
                        f.write(f"  {strategy_name}: å¤±æ•— - {result['error']}\n")
                        continue
                    
                    perf = result.get('performance_metrics', {})
                    unlearn = result.get('unlearning_metrics', {})
                    
                    f.write(f"  {strategy_name}:\n")
                    f.write(f"    ä¿ç•™æº–ç¢ºç‡: {perf.get('original_retain_acc', 0):.2f}% â†’ {perf.get('unlearned_retain_acc', 0):.2f}%\n")
                    f.write(f"    éºå¿˜æº–ç¢ºç‡: {perf.get('original_forget_acc', 0):.2f}% â†’ {perf.get('unlearned_forget_acc', 0):.2f}%\n")
                    f.write(f"    é»ƒé‡‘æ¨™æº– (ä¿ç•™/éºå¿˜): {perf.get('gs_retain_acc', 0):.2f}% / {perf.get('gs_forget_acc', 'N/A')}%\n")
                    f.write(f"    ZRF åˆ†æ•¸: {unlearn.get('zrf_score', 0):.4f}\n")
                    f.write(f"    éºå¿˜æ•ˆæœ: {unlearn.get('forget_effectiveness', 0):.4f}\n")
                    f.write(f"    ä¿ç•™ä¿æŒ: {unlearn.get('retain_preservation', 0):.4f}\n\n")
        
        self.logger.info(f"è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_path}")
        return report_path

    def _perform_statistical_analysis(self, all_results):
        """çµ±è¨ˆåˆ†æ"""
        analysis_path = f"{self.exp_dir}/results/statistical_analysis.txt"
        
        # æ”¶é›†æœ‰æ•ˆçµæœ
        valid_results = []
        for forget_key, strategies_results in all_results.items():
            for strategy_name, result in strategies_results.items():
                if 'error' not in result:
                    result_copy = result.copy()
                    result_copy['forget_key'] = forget_key
                    result_copy['strategy_name'] = strategy_name
                    valid_results.append(result_copy)
        
        if not valid_results:
            return
        
        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.write("WeightPruning çµ±è¨ˆåˆ†æ\n")
            f.write("="*30 + "\n\n")
            
            # æœ€ä½³ç­–ç•¥åˆ†æ
            f.write("1. æœ€ä½³ç­–ç•¥åˆ†æ:\n")
            f.write("-" * 20 + "\n")
            
            # æŒ‰ ZRF æ’åº
            zrf_results = [(r['forget_key'], r['strategy_name'], 
                           r.get('unlearning_metrics', {}).get('zrf_score', 0)) 
                          for r in valid_results]
            zrf_results.sort(key=lambda x: x[2], reverse=True)
            
            f.write("æŒ‰ ZRF åˆ†æ•¸æ’åº (å‰5å):\n")
            for i, (forget_key, strategy, zrf) in enumerate(zrf_results[:5], 1):
                f.write(f"  {i}. {forget_key}_{strategy}: {zrf:.4f}\n")
            
            # ç­–ç•¥å¹³å‡è¡¨ç¾
            f.write("\n2. ç­–ç•¥å¹³å‡è¡¨ç¾:\n")
            f.write("-" * 20 + "\n")
            
            strategy_stats = {}
            for result in valid_results:
                strategy = result['strategy_name']
                if strategy not in strategy_stats:
                    strategy_stats[strategy] = []
                
                zrf = result.get('unlearning_metrics', {}).get('zrf_score', 0)
                strategy_stats[strategy].append(zrf)
            
            for strategy, zrf_scores in strategy_stats.items():
                if zrf_scores:
                    avg_zrf = np.mean(zrf_scores)
                    std_zrf = np.std(zrf_scores)
                    f.write(f"  {strategy}: {avg_zrf:.4f} Â± {std_zrf:.4f} (n={len(zrf_scores)})\n")
            
            # è¦æ¨¡æ•ˆæ‡‰åˆ†æ
            f.write("\n3. è¦æ¨¡æ•ˆæ‡‰åˆ†æ:\n")
            f.write("-" * 20 + "\n")
            
            forget_stats = {}
            for result in valid_results:
                forget_key = result['forget_key']
                if forget_key not in forget_stats:
                    forget_stats[forget_key] = []
                
                zrf = result.get('unlearning_metrics', {}).get('zrf_score', 0)
                forget_stats[forget_key].append(zrf)
            
            for forget_key, zrf_scores in sorted(forget_stats.items()):
                if zrf_scores:
                    avg_zrf = np.mean(zrf_scores)
                    std_zrf = np.std(zrf_scores)
                    f.write(f"  {forget_key}: {avg_zrf:.4f} Â± {std_zrf:.4f} (n={len(zrf_scores)})\n")
        
        self.logger.info(f"çµ±è¨ˆåˆ†æå·²ä¿å­˜: {analysis_path}")
    
    def run_experiment(self, forget_classes, strategy_name, strategy_config, gs_info, global_step=0):
        """é‹è¡Œå–®å€‹WeightPruningå¯¦é©—"""
        # å»ºç«‹å¯¦é©—å°ˆç”¨ TensorBoard ç›®éŒ„
        exp_id = f"forget{len(forget_classes)}_{strategy_name}"
        run_tb_dir = os.path.join(self.tensorboard_dir, exp_id)
        gold_tb_dir = os.path.join(run_tb_dir, "gold_standard")
        os.makedirs(run_tb_dir, exist_ok=True)
        os.makedirs(gold_tb_dir, exist_ok=True)
        
        # å»ºç«‹ run summary writer
        writer = SummaryWriter(run_tb_dir)
        
        self.logger.info("="*80)
        self.logger.info(f"é–‹å§‹WeightPruningå¯¦é©—: {strategy_name}")
        self.logger.info(f"éºå¿˜é¡åˆ¥: {sorted(forget_classes)}")
        self.logger.info(f"ç­–ç•¥é…ç½®: {strategy_config}")
        self.logger.info("="*80)
        
        # åˆå§‹åŒ–MachineUnlearningæ¡†æ¶
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        temp_output_dir = f"./temp_weightpruning_{timestamp}"
        os.makedirs(temp_output_dir, exist_ok=True)
        
        try:
            mul = MachineUnlearning(
                model_class=VisionTransformer,
                model_args=self.model_args,
                batch_size=self.batch_size,
                device=self.device,
                output_dir=temp_output_dir,
                log_dir=gold_tb_dir,
                args=self.args,
            )
            
            # è¼‰å…¥æ¨¡å‹å’Œæº–å‚™æ•¸æ“š
            mul.load_original_model(self.base_model_path)
            mul.prepare_data(dataset_name='CIFAR100', forget_classes=forget_classes)

            # åˆå§‹åŒ–éš¨æ©Ÿæ¨¡å‹
            mul.init_random_model()
            
            # === æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥å¾ gs_info è¼‰å…¥GSçµæœï¼Œä¸å†è¨“ç·´ ===
            self.logger.info("å¾å¿«å–è¼‰å…¥é»ƒé‡‘æ¨™æº–æ¨¡å‹...")
            mul.retrained_model = gs_info["retrained_model_obj"]
            gs_metrics = gs_info["metrics"]
            gs_retain_acc = gs_metrics["gs_retain_acc"]
            gs_forget_acc = gs_metrics["gs_forget_acc"]
            retraining_time = gs_info["retraining_time"]
            # =======================================================

            # è©•ä¼°åŸå§‹æ¨¡å‹
            original_retain_acc = mul._evaluate_retain(mul.original_model)
            original_forget_acc = mul._evaluate_forget(mul.original_model)

            dist_dir = os.path.join(run_tb_dir, "distributions")
            mul.plot_forget_distributions(mul.original_model,  "original",  dist_dir, exp_id=exp_id)
            mul.plot_forget_distributions(mul.retrained_model, "gold",      dist_dir, exp_id=exp_id)
        
            # åŸ·è¡ŒWeightPruningéºå¿˜
            self.logger.info(f"åŸ·è¡ŒWeightPruningéºå¿˜: {strategy_name}")
            start_time = time.time()
            
            unlearner = WeightPruningUnlearner(mul.unlearned_model, self.device)
            mul.unlearned_model = unlearner.unlearn(
                retain_loader=mul.retain_train_loader,
                forget_loader=mul.forget_train_loader,
                fine_tune_epochs=self.fine_tune_epochs,
                **strategy_config,
            )

            unlearning_time = time.time() - start_time
            
            # è©•ä¼°éºå¿˜å¾Œçš„æ¨¡å‹
            unlearned_retain_acc = mul._evaluate_retain(mul.unlearned_model)
            unlearned_forget_acc = mul._evaluate_forget(mul.unlearned_model)

            mul.plot_forget_distributions(mul.unlearned_model, "unlearned", dist_dir, exp_id=exp_id)
            if mul.random_model is not None:
                mul.plot_forget_distributions(mul.random_model,  "random",    dist_dir, exp_id=exp_id)
    
            # å¢å¼·è©•ä¼°
            enhanced_results = {}
            if self.run_enhanced_eval:
                self.logger.info("åŸ·è¡Œå¢å¼·è©•ä¼°...")
                enhanced_results = enhanced_unlearning_evaluation(
                    mul.original_model, 
                    mul.unlearned_model, 
                    mul.retrained_model,
                    mul.random_model,
                    mul.retain_test_loader, 
                    mul.forget_test_loader, 
                    mul.retain_test_loader, 
                    self.device
                )
            
            # MIAè©•ä¼°
            mia_results = {'note': 'MIA disabled'}
            if self.run_mia:
                self.logger.info("åŸ·è¡ŒMIAè©•ä¼°...")
                mia_results = self._run_mia(mul, plot_mode="eval")
            
            # å¯«å…¥åŸºæœ¬æ‘˜è¦åˆ° TensorBoard
            experiment_step = global_step

            writer.add_scalar("Original/Retain_Acc", original_retain_acc, experiment_step)
            writer.add_scalar("Original/Forget_Acc", original_forget_acc, experiment_step)
            writer.add_scalar("Unlearned/Retain_Acc", unlearned_retain_acc, experiment_step)
            writer.add_scalar("Unlearned/Forget_Acc", unlearned_forget_acc, experiment_step)
            writer.add_scalar("GoldStandard/Retain_Acc", gs_retain_acc, experiment_step)
            
            if enhanced_results:
                writer.add_scalar("Unlearning/ZRF", enhanced_results.get('zrf_score', 0.0), experiment_step)
                writer.add_scalar("Unlearning/Alignment", enhanced_results.get('alignment_score', 0.0), experiment_step)
                writer.add_scalar("Unlearning/KL", enhanced_results.get('kl_divergence', 0.0), experiment_step)

            writer.add_scalar("Timing/Unlearning_Time", unlearning_time, experiment_step)
            writer.add_scalar("Experiment/Retraining_Time", retraining_time, experiment_step)

            writer.flush()
            
            # === Debug Diagnostics (Unlearned) ===
            diag = {}
            try:
                print("\n=== Debug Diagnostics (Unlearned) ===")
                # 1) head ç¶­åº¦å®Œæ•´æ€§ï¼ˆ confirm ä»ç‚º 100 é¡è¼¸å‡º ï¼‰
                mul.check_head_integrity(mul.unlearned_model)

                # 2) æª¢æŸ¥ head.weight æ˜¯å¦æœ‰ã€Œæ•´åˆ—å…¨ 0ã€çš„æƒ…æ³ï¼ˆzero-lock ç—•è·¡ï¼‰
                col_zero = mul.check_head_zero_columns(mul.unlearned_model, mul.forget_classes)
                if col_zero is not None:
                    total_zero_rows = int(col_zero.sum().item())
                    diag["head_zero_rows_total"] = total_zero_rows
                    if mul.forget_classes is not None:
                        fset = np.array(sorted(list(mul.forget_classes)))
                        # å®‰å…¨ï¼šclass id å¯èƒ½æœªæ’åº
                        forget_zero_rows = int(col_zero[fset].sum().item())
                        diag["head_zero_rows_in_forget"] = forget_zero_rows

                # 3) é æ¸¬åœ¨å¿˜è¨˜æ¸¬è©¦é›†ä¸Šçš„é¡åˆ¥è½é»ï¼ˆè½åœ¨ å¿˜è¨˜/ä¿ç•™ çš„æ¯”ä¾‹ï¼‰
                r_forget, r_retain = mul.debug_forget_prediction_stats(mul.unlearned_model)
                diag["pred_ratio_forget"] = float(r_forget)
                diag["pred_ratio_retain"] = float(r_retain)

                # 4) å¿˜è¨˜é›†çš„ã€ŒçœŸå¯¦é¡ logitã€ç›´æ–¹åœ–ï¼ˆæ•¸æ“šåŒ– + åœ–æª”ï¼‰
                diag_dir = os.path.join(run_tb_dir, "diagnostics")
                mul.plot_true_class_logit_hist(mul.unlearned_model, "unlearned", diag_dir)

                # å°ç…§ï¼šoriginal / gold ä¹Ÿå„ç•«ä¸€å¼µ
                mul.plot_true_class_logit_hist(mul.original_model,  "original",  diag_dir)
                mul.plot_true_class_logit_hist(mul.retrained_model, "gold",      diag_dir)

                # 5) å¿˜è¨˜é›†ä¸Šæœ€å¸¸è¢«é æ¸¬çš„é¡åˆ¥ï¼ˆTop-K å‡ºç¾æ¬¡æ•¸ï¼‰
                mul.top_predicted_classes_on_forget(mul.unlearned_model, topk=10)

            except Exception as e:
                self.logger.warning(f"è¨ºæ–·ç¨‹åºå¤±æ•—: {e}")

            # æ•´ç†çµæœ
            results = {
                'experiment_info': {
                    'method': 'WeightPruning',
                    'strategy': strategy_name,
                    'forget_classes': sorted(forget_classes),
                    'num_forget_classes': len(forget_classes),
                    'timestamp': timestamp,
                    "use_mixup": self.use_mixup,
                    "use_cutmix": self.use_cutmix,
                    "mix_alpha": self.mix_alpha,
                    "use_logit_penalty": self.use_logit_penalty,
                },
                'strategy_config': strategy_config,
                'performance_metrics': {
                    'original_retain_acc': original_retain_acc,
                    'original_forget_acc': original_forget_acc,
                    'unlearned_retain_acc': unlearned_retain_acc,
                    'unlearned_forget_acc': unlearned_forget_acc,
                    'gs_retain_acc': gs_retain_acc,
                    'gs_forget_acc': gs_forget_acc
                },
                'enhanced_metrics': enhanced_results,
                'mia_results': mia_results,
                'timing': {
                    'unlearning_time': unlearning_time,
                    'retraining_time': retraining_time
                }
            }
            
            unlearned_model_path = f"{self.exp_dir}/results/forget{len(forget_classes)}_{strategy_name}_unlearned_model.pth"
            torch.save(mul.unlearned_model.state_dict(), unlearned_model_path)
            results['unlearned_model_path'] = unlearned_model_path

            return results
            
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"WeightPruningå¯¦é©—å¤±æ•—: {error_msg}", exc_info=True)
            return {'error': error_msg, 'strategy': strategy_name}
        
        finally:
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if os.path.exists(temp_output_dir):
                shutil.rmtree(temp_output_dir, ignore_errors=True)
            writer.close()
    
    def _run_mia(self, mul, plot_mode="eval"):
        """é‹è¡Œå®Œæ•´çš„ MIA è©•ä¼° (mul_vit_1)"""
        try:
            mia = MembershipInferenceAttack(mul.unlearned_model, self.device)
            
            test_dataset = datasets.CIFAR100(
                root='./data', train=False, download=True,
                transform=transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))
                ])
            )
            test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)
            
            # æº–å‚™è³‡æ–™ï¼šretain+test ç”¨æ–¼è¨“ç·´ï¼Œretain+forget+test ç”¨æ–¼è©•ä¼°
            X_train, y_train, X_test, y_test, original_labels_test = mia.prepare_attack_data(
                mul.retain_test_loader,
                mul.forget_test_loader,
                test_loader
            )

            # å¾ X_train è£¡å†åˆ‡ 8:2 åšé©—è­‰
            split = int(0.8 * len(X_train))
            X_tr, y_tr = X_train[:split], y_train[:split]
            X_val, y_val = X_train[split:], y_train[split:]

            # è¨“ç·´æ”»æ“Šå™¨ (ä»¥ AUC é©…å‹•æ—©åœ)
            mia.train_attack_model(
                X_tr, y_tr, X_val, y_val,
                epochs=self.mia_epochs,
                learning_rate=self.mia_lr,
                use_scheduler=self.mia_use_scheduler
            )

            # æœ€çµ‚è©•ä¼° (retain+forget+test)
            mia_results = mia.evaluate_attack(X_test, y_test, original_labels_test)
            self.storage.save_results_to_json(
                self.exp_dir, mia_results, "mia_results.json"
            )
            
            # è¦–è¦ºåŒ–
            self.logger.info("ğŸ¨ é–‹å§‹ MIA ç‰¹å¾µè¦–è¦ºåŒ–åˆ†æ...")
            visualization_dir = os.path.join(self.exp_dir, "mia_visualization")
            os.makedirs(visualization_dir, exist_ok=True)

            # é‡æ–°æå–ç‰¹å¾µ (retain / forget / test)
            retain_features, retain_labels_orig = mia.extract_features(mul.unlearned_model, mul.retain_test_loader)
            forget_features, forget_labels_orig = mia.extract_features(mul.unlearned_model, mul.forget_test_loader)
            test_features, test_labels_orig = mia.extract_features(mul.unlearned_model, test_loader)

            # ä¿å­˜ä¸‰çµ„ç‰¹å¾µåˆ†å¸ƒ
            visualize_mia_features(
                retain_features, forget_features, test_features,
                output_dir=visualization_dir
            )

            print(f"[Debug] Before evaluate: X_test={X_test.shape}, y_test={len(y_test)}, labels={len(original_labels_test)}")

            if plot_mode == "eval":
                mia.plot_feature_distribution(
                    X_test, y_test, original_labels_test,
                    title="MIA Feature Distribution (Eval only)",
                    output_dir=visualization_dir
                )
            elif plot_mode == "all":
                # ç•« train+eval
                mia.plot_feature_distribution(
                    np.vstack([X_train, X_test]),
                    np.concatenate([y_train, y_test]),
                    np.concatenate([
                        np.full(len(y_train), -999),  # fake flag for train (é¿å… broadcast)
                        original_labels_test
                    ]),
                    title="MIA Feature Distribution (Train+Eval)",
                    output_dir=visualization_dir
                )

            return mia_results
        
        except Exception as e:
            logging.error("MIAè©•ä¼°å¤±æ•—: %s", e)
            return {'error': str(e), 'accuracy': 0.5}
    
    def run_all_strategies(self, forget_classes_list, strategies=None):
        """é‹è¡Œæ‰€æœ‰WeightPruningç­–ç•¥"""
        if strategies is None:
            unlearner = WeightPruningUnlearner(None, self.device)
            strategies = unlearner.get_strategy_configs(prune_ratios=self.prune_ratios)

        # å‰µå»ºå¯¦é©—ç›®éŒ„
        exp_dir = self.storage.create_experiment_dir("weight_pruning")
        
        all_results = {}
        
        for forget_classes in forget_classes_list:
            forget_key = f"forget{len(forget_classes)}"
            all_results[forget_key] = {}
            
            for strategy_name, strategy_config in strategies.items():
                logging.info("è™•ç†ç­–ç•¥: %s", strategy_name)
                
                try:
                    results = self.run_experiment(forget_classes, strategy_name, strategy_config)
                    all_results[forget_key][strategy_name] = results
                    
                    # ä¿å­˜å–®å€‹å¯¦é©—çµæœ
                    self.storage.save_results_to_json(
                        exp_dir, results, 
                        f"{forget_key}_{strategy_name}_results.json"
                    )
                    
                    logging.info("âœ“ %s å®Œæˆ", strategy_name)
                    
                except Exception as e:
                    logging.exception("âœ— %s å¤±æ•—: %s", strategy_name, e)
                    all_results[forget_key][strategy_name] = {'error': str(e)}
        
        # ä½¿ç”¨çµ±ä¸€çš„storageç³»çµ±ä¿å­˜çµæœ
        summary_csv, report_txt = self.storage.generate_comprehensive_summary(
            exp_dir, "WeightPruning", all_results
        )
        
        self.logger.info("WeightPruningå¯¦é©—å®Œæˆï¼")
        self.logger.info(f"çµæœç›®éŒ„: {exp_dir}")
        self.logger.info(f"CSVæ‘˜è¦: {summary_csv}")
        self.logger.info(f"è©³ç´°å ±å‘Š: {report_txt}")
        
        return exp_dir, all_results
    
    def _generate_summary_csv(self, exp_dir, all_results):
        """ç”Ÿæˆç¸½çµCSV"""
        
        summary_data = []
        for forget_key, strategies in all_results.items():
            for strategy_name, results in strategies.items():
                if 'error' in results:
                    continue
                
                row = {
                    'forget_classes': forget_key,
                    'strategy': strategy_name,
                    'prune_ratio': results['strategy_config'].get('prune_ratio', 0),
                    'prune_strategy': results['strategy_config'].get('prune_strategy', 'unknown'),
                    'original_retain_acc': results['performance_metrics']['original_retain_acc'],
                    'unlearned_retain_acc': results['performance_metrics']['unlearned_retain_acc'],
                    'unlearned_forget_acc': results['performance_metrics']['unlearned_forget_acc'],
                    'gs_retain_acc': results['performance_metrics']['gs_retain_acc'],
                    'gs_forget_acc': results['performance_metrics']['gs_forget_acc'],
                    'zrf_score': results['unlearning_metrics']['zrf_score'],
                    'unlearning_time': results['timing']['unlearning_time'],
                    'cosine_similarity': results['enhanced_metrics'].get('cosine_similarity', 0),
                    'mia_accuracy': results['mia_results'].get('accuracy', 0.5)
                }
                summary_data.append(row)
        
        df = pd.DataFrame(summary_data)
        summary_path = f"{exp_dir}/results/weight_pruning_summary.csv"
        df.to_csv(summary_path, index=False, encoding='utf-8')
        
        return summary_path
    
    def _generate_report(self, exp_dir, all_results):
        """ç”Ÿæˆè©³ç´°å ±å‘Š"""
        report_path = f"{exp_dir}/results/weight_pruning_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("WeightPruning éºå¿˜å¯¦é©—å ±å‘Š\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*80 + "\n\n")
            
            # å¯¦é©—æ¦‚è¿°
            total_experiments = sum(len(strategies) for strategies in all_results.values())
            successful_experiments = sum(
                len([s for s in strategies.values() if 'error' not in s])
                for strategies in all_results.values()
            )
            
            f.write(f"å¯¦é©—æ¦‚è¿°:\n")
            f.write(f"ç¸½å¯¦é©—æ•¸: {total_experiments}\n")
            f.write(f"æˆåŠŸå¯¦é©—æ•¸: {successful_experiments}\n")
            f.write(f"æˆåŠŸç‡: {100*successful_experiments/total_experiments:.1f}%\n\n")
            
            # ä¿®å‰ªç­–ç•¥åˆ†æ
            pruning_strategies = set()
            for strategies in all_results.values():
                for strategy_name, results in strategies.items():
                    if 'error' not in results:
                        pruning_strategies.add(results['strategy_config'].get('prune_strategy', 'unknown'))
            
            f.write(f"æ¸¬è©¦çš„ä¿®å‰ªç­–ç•¥: {', '.join(pruning_strategies)}\n")
            f.write(f"æ¸¬è©¦çš„ä¿®å‰ªæ¯”ä¾‹: 10%, 20%, 30%, 40%, 50%\n\n")
            
            # å„ç­–ç•¥è©³ç´°çµæœ
            for forget_key, strategies in all_results.items():
                f.write(f"\n{forget_key.upper()} çµæœ:\n")
                f.write("-"*50 + "\n")
                
                # æŒ‰ZRFåˆ†æ•¸æ’åº
                strategy_scores = []
                for strategy_name, results in strategies.items():
                    if 'error' not in results:
                        zrf = results['unlearning_metrics']['zrf_score']
                        strategy_scores.append((strategy_name, zrf, results))
                
                strategy_scores.sort(key=lambda x: x[1], reverse=True)
                
                for i, (strategy_name, zrf, results) in enumerate(strategy_scores, 1):
                    f.write(f"{i}. {strategy_name}:\n")
                    f.write(f"   ä¿®å‰ªç­–ç•¥: {results['strategy_config'].get('prune_strategy', 'unknown')}\n")
                    f.write(f"   ä¿®å‰ªæ¯”ä¾‹: {results['strategy_config'].get('prune_ratio', 0)*100:.0f}%\n")
                    f.write(f"   ZRFåˆ†æ•¸: {zrf:.4f}\n")
                    f.write(f"   ä¿ç•™æº–ç¢ºç‡: {results['performance_metrics']['unlearned_retain_acc']:.2f}%\n")
                    f.write(f"   ç¨€ç–åº¦å¢åŠ : {results['model_analysis'].get('sparsity_increase', 0)*100:.1f}%\n")
                    f.write(f"   å£“ç¸®æ¯”: {results['model_analysis'].get('compression_ratio', 1):.3f}\n")
                    f.write(f"   è¨“ç·´æ™‚é–“: {results['timing']['unlearning_time']:.1f}ç§’\n\n")
            
            # ä¿®å‰ªæ¯”ä¾‹vsæ•ˆæœåˆ†æ
            f.write("\nä¿®å‰ªæ¯”ä¾‹æ•ˆæœåˆ†æ:\n")
            f.write("-"*50 + "\n")
            
            ratios = [0.1, 0.2, 0.3, 0.4, 0.5]
            for ratio in ratios:
                ratio_results = []
                for strategies in all_results.values():
                    for results in strategies.values():
                        if ('error' not in results and 
                            results['strategy_config'].get('prune_ratio') == ratio):
                            ratio_results.append(results['unlearning_metrics']['zrf_score'])
                
                if ratio_results:
                    avg_zrf = sum(ratio_results) / len(ratio_results)
                    f.write(f"ä¿®å‰ª {ratio*100:.0f}%: å¹³å‡ZRF = {avg_zrf:.4f} ({len(ratio_results)}å€‹å¯¦é©—)\n")
            
            # ä¿®å‰ªç­–ç•¥æ¯”è¼ƒ
            f.write("\nä¿®å‰ªç­–ç•¥æ¯”è¼ƒ:\n")
            f.write("-"*50 + "\n")
            
            strategy_results = {}
            for strategies in all_results.values():
                for results in strategies.values():
                    if 'error' not in results:
                        strategy_type = results['strategy_config'].get('prune_strategy', 'unknown')
                        if strategy_type not in strategy_results:
                            strategy_results[strategy_type] = []
                        strategy_results[strategy_type].append(results['unlearning_metrics']['zrf_score'])
            
            for strategy_type, scores in strategy_results.items():
                avg_score = sum(scores) / len(scores)
                f.write(f"{strategy_type}: å¹³å‡ZRF = {avg_score:.4f} ({len(scores)}å€‹å¯¦é©—)\n")
            
            f.write("\n" + "="*80 + "\n")
        
        return report_path


def main():
    parser = argparse.ArgumentParser(description='WeightPruning éºå¿˜å¯¦é©—')
    
    # åŸºç¤åƒæ•¸
    parser.add_argument('--model_path', type=str, required=True, help='é è¨“ç·´æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--output_dir', type=str, default='./checkpoints', help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--device', type=str, default='cuda', help='é‹ç®—è¨­å‚™')
    
    # æ‰¹é‡å¯¦é©—åƒæ•¸
    parser.add_argument('--forget_class_counts', nargs='+', type=int, default=[10, 20, 30], 
                       help='æ‰¹é‡æ¸¬è©¦çš„éºå¿˜é¡åˆ¥æ•¸')
    parser.add_argument('--strategies', nargs='+', 
                       choices=['magnitude_reset', 'magnitude_zero_lock', 'gradient', 'fisher', 'all'], 
                       default=['magnitude_reset'], help='æ¸¬è©¦ç­–ç•¥')
    
    # æ¨¡å‹å’Œè¨“ç·´åƒæ•¸
    parser.add_argument('--batch_size', type=int, default=128, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4, help='æ•¸æ“šè¼‰å…¥ç·šç¨‹æ•¸')
    parser.add_argument('--unlearn_epochs', type=int, default=20, help='ä¿®å‰ªå¾Œå¾®èª¿çš„è¼ªæ•¸ (fine_tune_epochs)')

    # ä¿®å‰ªæ¯”ä¾‹
    parser.add_argument('--prune_ratios', nargs='+', type=float, default=[0.1, 0.2, 0.3, 0.4, 0.5],
                    help='ä¿®å‰ªæ¯”ä¾‹æ¸…å–® (0~1 ä¹‹é–“)ï¼Œæœƒå¥—ç”¨åˆ°æ‰€æœ‰æ”¯æ´æ¯”ä¾‹çš„ç­–ç•¥')
    parser.add_argument('--prune_target_layers',
                        type=str,
                        default='head,late_blocks',
                        help='è¦ä¿®å‰ªçš„å±¤ï¼Œé€—è™Ÿåˆ†éš”ã€‚å¯ç”¨: head, late_blocks, all_blocksï¼Œæˆ–è‡ªè¨‚å­å­—ä¸²ï¼ˆä¾‹å¦‚ blocks.7.attnï¼‰'
    )
    
    # é»ƒé‡‘æ¨™æº–åƒæ•¸
    parser.add_argument("--use_forget_uniform", action="store_true",help="æ˜¯å¦å•Ÿç”¨å¿˜è¨˜é›†é«˜ç†µå¾®èª¿ (KL -> uniform)")
    parser.add_argument("--use_forget_distill", action="store_true",help="æ˜¯å¦å•Ÿç”¨å¿˜è¨˜é›†è’¸é¤¾ (å°é½Š Gold)")
    parser.add_argument("--use_mixup", action="store_true",help="æ˜¯å¦åœ¨ GS è¨“ç·´ä¸­ä½¿ç”¨ Mixup è³‡æ–™å¢å¼·")
    parser.add_argument("--use_cutmix", action="store_true",help="æ˜¯å¦åœ¨ GS è¨“ç·´ä¸­ä½¿ç”¨ CutMix è³‡æ–™å¢å¼·")
    parser.add_argument('--mix_alpha', type=float, default=0.2, help='Mixup/CutMix çš„ Beta åˆ†å¸ƒåƒæ•¸ alpha')
    parser.add_argument("--use_logit_penalty", action="store_true",help="æ˜¯å¦åœ¨ GS è¨“ç·´ä¸­åŠ å…¥ logit ç¯„æ•¸æ‡²ç½°")
    parser.add_argument('--gs_epochs', type=int, default=250, help='é»ƒé‡‘æ¨™æº–è¨“ç·´è¼ªæ•¸')
    parser.add_argument('--gs_lr', type=float, default=1e-3, help='é»ƒé‡‘æ¨™æº–å­¸ç¿’ç‡')
    parser.add_argument('--gs_scheduler', type=str, default='onecycle', 
                       choices=['cosine', 'cosine_warmup', 'onecycle', 'step', 'plateau'], help='å­¸ç¿’ç‡èª¿åº¦å™¨')
    parser.add_argument('--gs_min_lr', type=float, default=1e-6, help='æœ€å°å­¸ç¿’ç‡')
    parser.add_argument('--gs_weight_decay', type=float, default=0.05, help='æ¬Šé‡è¡°æ¸›')
    
    parser.add_argument('--gs_use_ema', action='store_true', help='Use EMA during GS training/eval')
    parser.add_argument('--gs_ema_decay', type=float, default=0.999, help='EMA decay (beta) for GS')
    parser.add_argument('--gs_use_class_balance', action='store_true', help='Use class-balanced CE on retain set for GS')
    parser.add_argument('--gs_warmup_epochs', type=int, default=20, help='Warmup epochs for cosine_warmup scheduler')
    

    # è©•ä¼°åƒæ•¸
    parser.add_argument('--run_mia', action='store_true', help='åŸ·è¡ŒMIAè©•ä¼°')
    parser.add_argument('--no_mia', action='store_true', help='ä¸åŸ·è¡ŒMIAè©•ä¼°')
    parser.add_argument('--mia_epochs', type=int, default=30, help='MIAè¨“ç·´è¼ªæ•¸')
    parser.add_argument('--mia_lr', type=float, default=1e-3, help='MIAå­¸ç¿’ç‡')
    parser.add_argument('--run_enhanced_eval', action='store_true', default=True, help='åŸ·è¡Œå¢å¼·è©•ä¼°')
    parser.add_argument('--no_enhanced_eval', action='store_true', help='ä¸åŸ·è¡Œå¢å¼·è©•ä¼°')

    # Cosine Head åƒæ•¸
    parser.add_argument('--use_cosine_head', action='store_true', help='Use cosine classifier head for both GS/Unlearned')
    parser.add_argument('--cosine_scale', type=float, default=20.0, help='Scale s for cosine head logits')

    args = parser.parse_args()
    
    # è™•ç†åƒæ•¸
    if args.no_mia:
        args.run_mia = False
    if args.no_enhanced_eval:
        args.run_enhanced_eval = False
    
    print("ğŸš€ WeightPruning æ‰¹é‡éºå¿˜å¯¦é©—")
    print(f"ğŸ“Š æ¸¬è©¦é¡åˆ¥æ•¸: {args.forget_class_counts}")
    print(f"ğŸ”§ æ¸¬è©¦ç­–ç•¥: {args.strategies}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {args.output_dir}")
    
    # å»ºç«‹å¯¦é©—å¯¦ä¾‹
    experiment = WeightPruningExperiment(args)
    
    # åŸ·è¡Œæ‰¹é‡å¯¦é©—
    exp_dir, all_results = experiment.run_all_experiments(args.forget_class_counts, args.strategies)
    
    print("âœ… æ‰€æœ‰å¯¦é©—å®Œæˆ!")
    print(f"ğŸ“Š çµæœä¿å­˜åœ¨: {exp_dir}")
    print(f"ğŸ“ˆ TensorBoard: tensorboard --logdir={experiment.tensorboard_dir}")


if __name__ == "__main__":
    main()
