"""
LayerWise éºå¿˜å¯¦é©—ä¸»ç¨‹å¼
å®Œæ•´ç‰ˆæœ¬ - ä½¿ç”¨ç°¡æ½”æ—¥èªŒç³»çµ±
"""
import os
import sys
import time
import json
import argparse
import torch
import torch.nn as nn
import pandas as pd
import shutil
import random
import numpy as np
import logging
from datetime import datetime
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.vit_LSA_classattn import VisionTransformer
from methods.layerwise_unlearner import LayerWiseUnlearner
from utils.evaluation_utils import enhanced_unlearning_evaluation, calculate_model_size_difference
from utils.storage_utils import ExperimentStorage
from mul_vit_1 import MachineUnlearning, MembershipInferenceAttack

def generate_forget_classes(num_classes, total_classes=100, seed=42):
    """
    ç”Ÿæˆå›ºå®šçš„éºå¿˜é¡åˆ¥åˆ—è¡¨
    
    Args:
        num_classes: è¦éºå¿˜çš„é¡åˆ¥æ•¸é‡
        total_classes: ç¸½é¡åˆ¥æ•¸
        seed: éš¨æ©Ÿç¨®å­
    
    Returns:
        set: éºå¿˜é¡åˆ¥çš„é›†åˆ
    """
    random.seed(seed + num_classes)
    np.random.seed(seed + num_classes)
    
    forget_classes = set(random.sample(range(total_classes), num_classes))
    return forget_classes


class LayerWiseExperiment:
    """LayerWise éºå¿˜å¯¦é©—ç®¡ç†å™¨ - ä½¿ç”¨çµ±ä¸€çš„Storageç³»çµ±"""
    
    def __init__(self, args):
        self.args = args
        self.base_model_path = args.model_path
        self.device = args.device if hasattr(args, 'device') else 'cuda'
        
        # ä½¿ç”¨çµ±ä¸€çš„å„²å­˜ç³»çµ±
        self.storage = ExperimentStorage(args.output_dir)
        
        # å‰µå»ºå®Œæ•´å¯¦é©—çµæ§‹
        self.exp_dir, self.exp_name = self.storage.create_complete_experiment_structure("layerwise")
        
        # è¨­ç½®æ—¥èªŒç³»çµ±
        self.logger, self.log_file = self.storage.setup_logging_system(self.exp_dir, self.exp_name)
        
        # è¨­ç½®TensorBoard
        self.tensorboard_dir, self.main_writer = self.storage.setup_tensorboard(self.exp_dir)
        
        self.logger.info(f"TensorBoardç›®éŒ„: {self.tensorboard_dir}")
        self.logger.info("ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹TensorBoard:")
        self.logger.info(f"  tensorboard --logdir={self.tensorboard_dir}")
    
        # æ¨¡å‹åƒæ•¸
        self.model_args = {
            'img_size': 32,
            'patch_size': 4,
            'in_chans': 3,
            'num_classes': 100,
            'embed_dim': 300,
            'depth': 10,
            'num_heads': 12,
            'mlp_ratio': 4.0,
            'qkv_bias': True,
            'drop_rate': 0.0,
            'attn_drop_rate': 0.0,
            'drop_path_rate': 0.05,
            'is_LSA': True
        }
        
        # ä¿å­˜å®Œæ•´é…ç½®ä¸¦è¨˜éŒ„å¯¦é©—é–‹å§‹
        config_file, self.config = self.storage.save_complete_experiment_config(
            self.exp_dir, "LayerWise", args, self.model_args
        )
        
        # çµ±ä¸€çš„å¯¦é©—é–‹å§‹æ—¥èªŒ
        self.storage.log_experiment_start(
            self.logger, "LayerWise", self.exp_name, self.exp_dir, self.config, args
        )
        
        print(f"ğŸš€ LayerWiseå¯¦é©—é–‹å§‹ - ç›®éŒ„: {self.exp_dir}")
    def run_single_experiment(self, forget_classes, strategy_name, strategy_config):
        """é‹è¡Œå–®å€‹LayerWiseå¯¦é©—"""
        experiment_start_time = time.time()
        
        # ç‚ºæ¯å€‹å¯¦é©—å‰µå»ºç¨ç«‹çš„writer
        exp_id = f"forget{len(forget_classes)}_{strategy_name}"
        run_tb_dir = os.path.join(self.tensorboard_dir, exp_id)
        os.makedirs(run_tb_dir, exist_ok=True)
        writer = SummaryWriter(run_tb_dir)

        # å¯¦é©—é–‹å§‹è¨˜éŒ„
        self.logger.info("\n" + "="*60)
        self.logger.info(f"é–‹å§‹å¯¦é©—: {strategy_name}")
        self.logger.info(f"éºå¿˜é¡åˆ¥æ•¸é‡: {len(forget_classes)}")
        self.logger.info(f"éºå¿˜é¡åˆ¥: {sorted(forget_classes)}")
        self.logger.info(f"ç­–ç•¥é…ç½®: {strategy_config}")
        self.logger.info("="*60)
        
        print(f"\nğŸ¯ åŸ·è¡Œ {strategy_name} (éºå¿˜{len(forget_classes)}é¡)")
        
        # ä½¿ç”¨è‡¨æ™‚ç›®éŒ„
        temp_dir = f"./temp_layerwise_{strategy_name}_{int(time.time())}"
        os.makedirs(temp_dir, exist_ok=True)
        
        try:
            # === éšæ®µ1: åˆå§‹åŒ– ===
            self.logger.info("éšæ®µ1: åˆå§‹åŒ–å¯¦é©—æ¡†æ¶")
            
            # å»ºç«‹ GS çš„ TensorBoard ç›®éŒ„
            gold_tb_dir = os.path.join(run_tb_dir, "gold_standard")
            os.makedirs(gold_tb_dir, exist_ok=True)
            
            mul = MachineUnlearning(
                model_class=VisionTransformer,
                model_args=self.model_args,
                device=self.device,
                output_dir=temp_dir,
                log_dir=gold_tb_dir  # ç›´æ¥æŒ‡å®š GS è¨“ç·´æ›²ç·šè¼¸å‡ºä½ç½®
            )
            
            # === éšæ®µ2: è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š ===
            self.logger.info("éšæ®µ2: è¼‰å…¥æ¨¡å‹å’Œæº–å‚™æ•¸æ“š")
            mul.load_original_model(self.base_model_path)
            mul.prepare_data(dataset_name='CIFAR100', forget_classes=forget_classes)
            
            self.logger.info(f"ä¿ç•™è¨“ç·´é›†å¤§å°: {len(mul.retain_train_loader.dataset)}")
            self.logger.info(f"éºå¿˜è¨“ç·´é›†å¤§å°: {len(mul.forget_train_loader.dataset)}")
            
            # === éšæ®µ3: è©•ä¼°åŸå§‹æ¨¡å‹ ===
            self.logger.info("éšæ®µ3: è©•ä¼°åŸå§‹æ¨¡å‹æ€§èƒ½")
            original_retain_acc = mul._evaluate_retain(mul.original_model)
            original_forget_acc = mul._evaluate_forget(mul.original_model)
            
            self.logger.info(f"åŸå§‹æ¨¡å‹ - ä¿ç•™æº–ç¢ºç‡: {original_retain_acc:.4f}%")
            self.logger.info(f"åŸå§‹æ¨¡å‹ - éºå¿˜æº–ç¢ºç‡: {original_forget_acc:.4f}%")
            
            print(f"ğŸ“Š åŸå§‹: ä¿ç•™ {original_retain_acc:.2f}% | éºå¿˜ {original_forget_acc:.2f}%")
            
            # === éšæ®µ4: è¨“ç·´é»ƒé‡‘æ¨™æº– ===
            if not hasattr(mul, 'retrained_model') or mul.retrained_model is None:
                self.logger.info("éšæ®µ4: è¨“ç·´é»ƒé‡‘æ¨™æº–æ¨¡å‹")
                print("ğŸ† è¨“ç·´é»ƒé‡‘æ¨™æº–æ¨¡å‹...")

                mul.train_gold_standard(
                    epochs=self.args.gs_epochs,
                    lr=self.args.gs_lr,
                    lr_scheduler_type=self.args.gs_lr_scheduler,
                    weight_decay=self.args.gs_weight_decay,
                )
                
            else:
                self.logger.info("éšæ®µ4: ä½¿ç”¨æ—¢æœ‰é»ƒé‡‘æ¨™æº–æ¨¡å‹")
            
            gs_retain_acc = mul._evaluate_retain(mul.retrained_model)
            self.logger.info(f"é»ƒé‡‘æ¨™æº–æ¨¡å‹ - ä¿ç•™æº–ç¢ºç‡: {gs_retain_acc:.4f}%")
            print(f"ğŸ† é»ƒé‡‘æ¨™æº–: ä¿ç•™ {gs_retain_acc:.2f}%")
            
            # === éšæ®µ5: åŸ·è¡ŒLayerWiseéºå¿˜ ===
            self.logger.info("éšæ®µ5: åŸ·è¡ŒLayerWiseéºå¿˜")
            unlearn_start = time.time()
            
            print(f"ğŸ§  åŸ·è¡ŒLayerWiseéºå¿˜ ({strategy_name})...")
            
            unlearner = LayerWiseUnlearner(mul.unlearned_model, self.device)
            
            # æº–å‚™éºå¿˜åƒæ•¸
            unlearn_params = {
                'retain_loader': mul.retain_train_loader,
                'forget_loader': mul.forget_train_loader,
                'epochs': self.args.unlearn_epochs,
                'lr': self.args.unlearn_lr,
                # 'lr_scheduler_type': self.args.unlearn_lr_scheduler,
                'class_mapping': mul.class_mapping,
                'num_retain_classes': mul.num_retain_classes,
                **strategy_config
            }
            
            mul.unlearned_model = unlearner.unlearn(**unlearn_params)
            unlearning_time = time.time() - unlearn_start
            
            self.logger.info(f"LayerWiseéºå¿˜å®Œæˆï¼Œç”¨æ™‚: {unlearning_time:.2f}ç§’")
            
            # === éšæ®µ6: è©•ä¼°éºå¿˜æ¨¡å‹ ===
            self.logger.info("éšæ®µ6: è©•ä¼°éºå¿˜å¾Œæ¨¡å‹")
            
            unlearned_retain_acc = mul._evaluate_retain(mul.unlearned_model)
            unlearned_forget_acc = mul._evaluate_forget(mul.unlearned_model)
            
            self.logger.info(f"éºå¿˜æ¨¡å‹ - ä¿ç•™æº–ç¢ºç‡: {unlearned_retain_acc:.4f}%")
            self.logger.info(f"éºå¿˜æ¨¡å‹ - éºå¿˜æº–ç¢ºç‡: {unlearned_forget_acc:.4f}%")
            
            print(f"ğŸ“Š éºå¿˜å¾Œ: ä¿ç•™ {unlearned_retain_acc:.2f}% | éºå¿˜ {unlearned_forget_acc:.2f}%")
            
            # è¨ˆç®—é—œéµæŒ‡æ¨™
            retain_preservation = unlearned_retain_acc / max(original_retain_acc, 1e-6)
            forget_effectiveness = (original_forget_acc - (unlearned_forget_acc or 0)) / max(original_forget_acc, 1e-6)
            
            self.logger.info(f"ä¿ç•™èƒ½åŠ›ä¿æŒç‡: {retain_preservation:.4f}")
            self.logger.info(f"éºå¿˜æœ‰æ•ˆæ€§: {forget_effectiveness:.4f}")
            
            # å¯«å…¥åŸºæœ¬æ‘˜è¦åˆ° run æ ¹ç›®éŒ„
            writer.add_scalar("Original/Retain_Acc", original_retain_acc, 0)
            writer.add_scalar("Original/Forget_Acc", original_forget_acc, 0)
            writer.add_scalar("Unlearned/Retain_Acc", unlearned_retain_acc, 0)
            writer.add_scalar("Unlearned/Forget_Acc", unlearned_forget_acc, 0)
            writer.add_scalar("GoldStandard/Retain_Acc", gs_retain_acc, 0)
            
            # === éšæ®µ7: å¢å¼·è©•ä¼° ===
            enhanced_results = {}
            if self.args.run_enhanced_eval:
                self.logger.info("éšæ®µ7: åŸ·è¡Œå¢å¼·è©•ä¼°")
                print("ğŸ“ˆ åŸ·è¡Œå¢å¼·è©•ä¼°...")
                
                enhanced_results = enhanced_unlearning_evaluation(
                    mul.original_model, mul.unlearned_model, mul.retrained_model,
                    mul.retain_test_loader, mul.forget_test_loader,
                    mul.retain_test_loader, self.device
                )
                
                # è¨˜éŒ„è©³ç´°çš„å¢å¼·è©•ä¼°çµæœ
                self.logger.info("å¢å¼·è©•ä¼°çµæœ:")
                for metric, value in enhanced_results.items():
                    if isinstance(value, (int, float)):
                        self.logger.info(f"  {metric}: {value:.6f}")
                
                zrf_score = enhanced_results.get('zrf_score', 0)
                self.logger.info(f"ZRFåˆ†æ•¸: {zrf_score:.6f}")
                print(f"ğŸ¯ ZRFåˆ†æ•¸: {zrf_score:.4f}")
                
                # å¯«å…¥å¢å¼·è©•ä¼°æ¨™é‡
                writer.add_scalar("Unlearning/ZRF", zrf_score, 0)
                writer.add_scalar("Unlearning/KL", enhanced_results.get('kl_divergence', 0.0), 0)
            
            # === éšæ®µ8: å®Œæ•´MIAè©•ä¼° ===
            mia_results = {}
            if self.args.run_mia:
                self.logger.info("éšæ®µ8: åŸ·è¡Œå®Œæ•´MIAè©•ä¼°")
                print("ğŸ•µï¸ åŸ·è¡ŒMIAè©•ä¼°...")
                
                try:
                    mia_results = self._run_comprehensive_mia(mul)
                    
                    # è¨˜éŒ„è©³ç´°MIAçµæœ
                    self.logger.info("MIAè©•ä¼°çµæœ:")
                    for metric, value in mia_results.items():
                        if isinstance(value, (int, float)):
                            self.logger.info(f"  MIA {metric}: {value:.6f}")
                    
                    mia_acc = mia_results.get('accuracy', 0.5)
                    print(f"ğŸ•µï¸ MIAæº–ç¢ºç‡: {mia_acc:.4f}")
                    
                except Exception as e:
                    self.logger.warning(f"MIAè©•ä¼°å¤±æ•—: {e}")
                    self.logger.debug("MIAéŒ¯èª¤è©³æƒ…:", exc_info=True)
                    mia_results = {'error': str(e), 'accuracy': 0.5}
            
            # === è¨ˆç®—æ¨¡å‹åˆ†æ ===
            model_size_info = {}
            try:
                model_size_info = calculate_model_size_difference(
                    mul.original_model, mul.unlearned_model
                )
                self.logger.info("æ¨¡å‹å¤§å°åˆ†æ:")
                for key, value in model_size_info.items():
                    self.logger.info(f"  {key}: {value}")
            except Exception as e:
                self.logger.warning(f"æ¨¡å‹åˆ†æå¤±æ•—: {e}")
            
            # === æ•´ç†å®Œæ•´çµæœ ===
            total_experiment_time = time.time() - experiment_start_time
            
            results = {
                'experiment_info': {
                    'method': 'LayerWise',
                    'strategy': strategy_name,
                    'forget_classes': sorted(forget_classes),
                    'num_forget_classes': len(forget_classes),
                    'timestamp': datetime.now().isoformat(),
                    'total_experiment_time': total_experiment_time
                },
                'strategy_config': strategy_config,
                'performance_metrics': {
                    'original_retain_acc': original_retain_acc,
                    'original_forget_acc': original_forget_acc,
                    'unlearned_retain_acc': unlearned_retain_acc,
                    'unlearned_forget_acc': unlearned_forget_acc,
                    'gs_retain_acc': gs_retain_acc
                },
                'unlearning_metrics': {
                    'zrf_score': enhanced_results.get('zrf_score', 0),
                    'kl_divergence': enhanced_results.get('kl_divergence', 0),
                    'forget_effectiveness': forget_effectiveness,
                    'retain_preservation': retain_preservation
                },
                'enhanced_metrics': enhanced_results,
                'model_analysis': model_size_info,
                'mia_results': mia_results,
                'timing': {
                    'unlearning_time': unlearning_time,
                    'total_experiment_time': total_experiment_time
                }
            }
            
            # ä¿å­˜æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.args.save_models:
                self._save_models(mul, strategy_name, len(forget_classes))
            
            # è¨˜éŒ„å¯¦é©—å®Œæˆ
            self.logger.info("\n" + "="*60)
            self.logger.info(f"å¯¦é©— {strategy_name} æˆåŠŸå®Œæˆï¼")
            self.logger.info(f"ç¸½ç”¨æ™‚: {total_experiment_time:.2f}ç§’")
            self.logger.info(f"ZRFåˆ†æ•¸: {enhanced_results.get('zrf_score', 0):.6f}")
            self.logger.info("="*60)
            
            print(f"âœ… {strategy_name} å®Œæˆ - ZRF: {enhanced_results.get('zrf_score', 0):.4f}")
            
            return results
            
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"å¯¦é©— {strategy_name} å¤±æ•—: {error_msg}")
            self.logger.error("è©³ç´°éŒ¯èª¤ä¿¡æ¯:", exc_info=True)
            print(f"âŒ {strategy_name} å¤±æ•—: {error_msg}")
            return {'error': error_msg, 'strategy': strategy_name}
        
        finally:
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)
    
    def _run_comprehensive_mia(self, mul):
        """é‹è¡Œå®Œæ•´çš„MIAè©•ä¼°"""
        self.logger.info("é–‹å§‹å®Œæ•´MIAè©•ä¼°æµç¨‹...")
        
        try:
            # å‰µå»ºMIAæ”»æ“Šå™¨
            mia = MembershipInferenceAttack(
                target_model=mul.unlearned_model,
                device=self.device
            )
            
            self.logger.info("å‰µå»ºCIFAR100æ¸¬è©¦æ•¸æ“šé›†...")
            # å‰µå»ºå®Œæ•´çš„æ¸¬è©¦æ•¸æ“šé›†
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))
            ])
            
            test_dataset = datasets.CIFAR100(
                root='./data', train=False, download=True, transform=transform
            )
            test_loader = DataLoader(
                test_dataset, 
                batch_size=self.args.batch_size, 
                shuffle=False, 
                num_workers=getattr(self.args, 'num_workers', 4)
            )
            
            self.logger.info("æº–å‚™MIAæ”»æ“Šæ•¸æ“š...")
            # æº–å‚™æ”»æ“Šæ•¸æ“š
            X_train, y_train, X_test, y_test, original_labels_test = mia.prepare_attack_data(
                mul.retain_test_loader, 
                mul.forget_test_loader, 
                test_loader,
            )
            
            # å¯è¦–åŒ–ä¸¦ä¿å­˜ç‰¹å¾µåˆ†å¸ƒåœ–
            mia.plot_feature_distribution(
                np.vstack([X_train, X_test]), 
                np.concatenate([y_train, y_test]), 
                title="MIA Feature Distribution", 
                output_dir=self.exp_dir
            )

            self.logger.info(f"MIAè¨“ç·´é›†å¤§å°: {len(X_train)}")
            self.logger.info(f"MIAæ¸¬è©¦é›†å¤§å°: {len(X_test)}")
            
            # è¨“ç·´MIAæ”»æ“Šæ¨¡å‹
            self.logger.info("è¨“ç·´MIAæ”»æ“Šæ¨¡å‹...")
            mia_epochs = self.args.mia_epochs
            mia_lr = getattr(self.args, 'mia_lr', 1e-3)
            use_scheduler = getattr(self.args, 'mia_use_scheduler', True)
            
            mia.train_attack_model(
                X_train, y_train, X_test, y_test, 
                epochs=mia_epochs,
                learning_rate=mia_lr,
                use_scheduler=use_scheduler
            )
            
            self.logger.info("è©•ä¼°MIAæ”»æ“Šæ•ˆæœ...")
            # è©•ä¼°æ”»æ“Šæ•ˆæœ
            mia_results = mia.evaluate_attack(X_test, y_test, original_labels_test)
            
            self.logger.info("MIAè©•ä¼°å®Œæˆ")
            return mia_results
            
        except Exception as e:
            self.logger.error(f"MIAè©•ä¼°éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            self.logger.debug("MIAéŒ¯èª¤è©³ç´°å †æ£§:", exc_info=True)
            
            # è¿”å›é»˜èªå€¼è€Œä¸æ˜¯å´©æ½°
            return {
                'error': str(e),
                'accuracy': 0.5,
                'retain_acc': 0.5,
                'forget_acc': 0.5,
                'precision': 0.5,
                'recall': 0.5,
                'f1_score': 0.5
            }
    
    def _save_models(self, mul, strategy_name, num_forget_classes):
        """ä¿å­˜æ¨¡å‹"""
        model_dir = f"{self.exp_dir}/models/forget{num_forget_classes}_{strategy_name}"
        os.makedirs(model_dir, exist_ok=True)
        
        # ä¿å­˜å„å€‹æ¨¡å‹
        torch.save(mul.unlearned_model.state_dict(), 
                   f"{model_dir}/unlearned_model.pth")
        
        if hasattr(mul, 'retrained_model') and mul.retrained_model is not None:
            torch.save(mul.retrained_model.state_dict(), 
                       f"{model_dir}/gold_standard_model.pth")
        
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    
    def run_all_experiments(self, forget_classes_configs):
        """é‹è¡Œæ‰€æœ‰LayerWiseå¯¦é©—"""
        # ç²å–ç­–ç•¥é…ç½®
        temp_unlearner = LayerWiseUnlearner(None, self.device)
        strategies = temp_unlearner.get_strategy_configs()
        
        # ç¯©é¸ç­–ç•¥
        if hasattr(self.args, 'strategies') and 'all' not in self.args.strategies:
            strategies = {name: config for name, config in strategies.items()
                         if name in self.args.strategies}
        
        total_experiments = len(forget_classes_configs) * len(strategies)
        
        # è©³ç´°çš„å¯¦é©—è¨ˆåŠƒè¨˜éŒ„
        self.logger.info("\n" + "="*80)
        self.logger.info("å¯¦é©—åŸ·è¡Œè¨ˆåŠƒ")
        self.logger.info("="*80)
        self.logger.info(f"ç¸½å¯¦é©—æ•¸é‡: {total_experiments}")
        self.logger.info(f"éºå¿˜é¡åˆ¥é…ç½®: {len(forget_classes_configs)} ç¨®")
        self.logger.info(f"LayerWiseç­–ç•¥: {len(strategies)} ç¨®")
        
        self.logger.info("\néºå¿˜é¡åˆ¥è©³æƒ…:")
        for config in forget_classes_configs:
            self.logger.info(f"  {config['num_classes']}é¡: {sorted(config['classes'])}")
        
        self.logger.info(f"\nLayerWiseç­–ç•¥è©³æƒ…:")
        for name, config in strategies.items():
            self.logger.info(f"  {name}: {config}")
        
        self.logger.info("="*80)
        
        # æ§åˆ¶å°è¼¸å‡ºè¨ˆåŠƒæ‘˜è¦
        print(f"\nğŸ“‹ å¯¦é©—è¨ˆåŠƒ: {total_experiments} å€‹å¯¦é©—")
        print(f"ğŸ¯ é¡åˆ¥é…ç½®: {[c['num_classes'] for c in forget_classes_configs]}")
        print(f"ğŸ”§ ç­–ç•¥: {list(strategies.keys())}")
        
        all_results = {}
        experiment_count = 0
        successful_experiments = 0
        failed_experiments = 0
        
        # ä½¿ç”¨é€²åº¦æ¢
        with tqdm(total=total_experiments, desc="LayerWiseå¯¦é©—ç¸½é€²åº¦", position=0) as main_pbar:
            
            for config_idx, config in enumerate(forget_classes_configs, 1):
                num_classes = config['num_classes']
                forget_classes = config['classes']
                forget_key = f"forget{num_classes}"
                all_results[forget_key] = {}
                
                self.logger.info(f"\nè™•ç†éºå¿˜é…ç½® {config_idx}/{len(forget_classes_configs)}: {num_classes} å€‹é¡åˆ¥")
                self.logger.info(f"éºå¿˜é¡åˆ¥: {sorted(forget_classes)}")
                
                print(f"\nğŸ“ è™•ç† {forget_key} ({config_idx}/{len(forget_classes_configs)})")
                
                # ä¿å­˜ç•¶å‰é…ç½®çš„è©³ç´°åƒæ•¸
                args_path = f"{self.exp_dir}/configs/{forget_key}_experiment_args.txt"
                self._save_detailed_args_file(args_path, config, strategies)
                
                for strategy_name, strategy_config in strategies.items():
                    experiment_count += 1
                    
                    # æ›´æ–°é€²åº¦æ¢æè¿°
                    main_pbar.set_description(f"åŸ·è¡Œ {strategy_name} (å¿˜è¨˜{num_classes}é¡) [{experiment_count}/{total_experiments}]")
                    
                    try:
                        # åŸ·è¡Œå–®å€‹å¯¦é©—
                        results = self.run_single_experiment(
                            forget_classes, strategy_name, strategy_config
                        )
                        
                        all_results[forget_key][strategy_name] = results
                        
                        # ä¿å­˜å–®å€‹å¯¦é©—çµæœ
                        result_file = f"{self.exp_dir}/results/{forget_key}_{strategy_name}_detailed.json"
                        with open(result_file, 'w', encoding='utf-8') as f:
                            json.dump(results, f, indent=2, ensure_ascii=False)
                        
                        # æ›´æ–°çµ±è¨ˆ
                        if 'error' not in results:
                            successful_experiments += 1
                            zrf = results['unlearning_metrics']['zrf_score']
                            
                            # æ›´æ–°é€²åº¦æ¢å¾Œç¶´
                            main_pbar.set_postfix({
                                'ZRF': f"{zrf:.3f}",
                                'Success': f"{successful_experiments}/{experiment_count}"
                            })
                            
                            self.logger.info(f"âœ“ {strategy_name} æˆåŠŸå®Œæˆ - ZRF: {zrf:.6f}")
                        else:
                            failed_experiments += 1
                            main_pbar.set_postfix({
                                'Success': f"{successful_experiments}/{experiment_count}",
                                'Failed': failed_experiments
                            })
                            self.logger.error(f"âœ— {strategy_name} å¤±æ•—: {results['error']}")
                        
                    except Exception as e:
                        error_msg = str(e)
                        all_results[forget_key][strategy_name] = {'error': error_msg}
                        failed_experiments += 1
                        
                        self.logger.error(f"âœ— {strategy_name} ç•°å¸¸: {error_msg}")
                        self.logger.error("è©³ç´°ç•°å¸¸ä¿¡æ¯:", exc_info=True)
                        print(f"âŒ {strategy_name} ç•°å¸¸")
                    
                    # æ›´æ–°ä¸»é€²åº¦æ¢
                    main_pbar.update(1)
                
                # ç•¶å‰é…ç½®å®Œæˆæ‘˜è¦
                self.logger.info(f"\n{forget_key} é…ç½®å®Œæˆ:")
                self.logger.info(f"  æˆåŠŸ: {sum(1 for r in all_results[forget_key].values() if 'error' not in r)}/{len(strategies)}")
                self.logger.info(f"  å¤±æ•—: {sum(1 for r in all_results[forget_key].values() if 'error' in r)}/{len(strategies)}")
        
        # å¯¦é©—å®Œæˆç¸½çµ
        self.logger.info("\n" + "="*80)
        self.logger.info("æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
        self.logger.info("="*80)
        self.logger.info(f"ç¸½å¯¦é©—æ•¸: {experiment_count}")
        self.logger.info(f"æˆåŠŸå¯¦é©—: {successful_experiments}")
        self.logger.info(f"å¤±æ•—å¯¦é©—: {failed_experiments}")
        self.logger.info(f"æˆåŠŸç‡: {successful_experiments/max(experiment_count,1)*100:.2f}%")
        
        # ä½¿ç”¨çµ±ä¸€çš„storageç³»çµ±ç”Ÿæˆå ±å‘Š
        self.logger.info("\nç”Ÿæˆå¯¦é©—å ±å‘Š...")
        summary_csv, report_txt = self.storage.generate_comprehensive_summary(
            self.exp_dir, "LayerWise", all_results
        )
        
        self.logger.info(f"CSVç¸½çµå ±å‘Š: {summary_csv}")
        self.logger.info(f"è©³ç´°æ–‡å­—å ±å‘Š: {report_txt}")
        self.logger.info("="*80)
        
        # æ§åˆ¶å°æœ€çµ‚æ‘˜è¦
        print(f"\nğŸ‰ LayerWiseå¯¦é©—å…¨éƒ¨å®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸç‡: {successful_experiments}/{experiment_count} ({successful_experiments/max(experiment_count,1)*100:.1f}%)")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.exp_dir}")
        
        return self.exp_dir, all_results
    
    def _save_detailed_args_file(self, args_path, config, strategies):
        """ä¿å­˜è©³ç´°çš„åƒæ•¸æ–‡ä»¶"""
        with open(args_path, 'w', encoding='utf-8') as f:
            f.write(f"# LayerWiseéºå¿˜å¯¦é©—è©³ç´°åƒæ•¸\n")
            f.write(f"# ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# å¯¦é©—ç›®éŒ„: {self.exp_dir}\n\n")
            
            f.write("=== åŸºæœ¬ä¿¡æ¯ ===\n")
            f.write(f"method: LayerWise\n")
            f.write(f"model_path: {self.base_model_path}\n")
            f.write(f"device: {self.device}\n")
            f.write(f"experiment_name: {self.exp_name}\n\n")
            
            f.write("=== éºå¿˜é…ç½® ===\n")
            f.write(f"num_forget_classes: {config['num_classes']}\n")
            f.write(f"forget_classes: {','.join(map(str, sorted(config['classes'])))}\n")
            f.write(f"seed: {config['seed']}\n\n")
            
            f.write("=== LayerWiseç­–ç•¥ ===\n")
            for name, strategy_config in strategies.items():
                f.write(f"{name}: {strategy_config}\n")
            f.write("\n")
            
            f.write("=== è¨“ç·´åƒæ•¸ ===\n")
            f.write(f"unlearn_epochs: {self.args.unlearn_epochs}\n")
            f.write(f"unlearn_lr: {self.args.unlearn_lr}\n")
            f.write(f"batch_size: {self.args.batch_size}\n\n")
            
            f.write("=== MIAåƒæ•¸ ===\n")
            f.write(f"run_mia: {self.args.run_mia}\n")
            f.write(f"mia_epochs: {self.args.mia_epochs}\n")
            f.write(f"mia_lr: {getattr(self.args, 'mia_lr', 1e-3)}\n")
    
    def _generate_comprehensive_csv(self, all_results):
        """ç”Ÿæˆè©³ç´°çš„CSVå ±å‘Š"""
        summary_data = []
        
        for forget_key, strategies in all_results.items():
            for strategy_name, results in strategies.items():
                if 'error' in results:
                    continue
                
                row = {
                    'forget_classes': forget_key,
                    'strategy': strategy_name,
                    'num_forget_classes': results['experiment_info']['num_forget_classes'],
                    'forget_classes_list': ','.join(map(str, results['experiment_info']['forget_classes'])),
                    'original_retain_acc': results['performance_metrics']['original_retain_acc'],
                    'unlearned_retain_acc': results['performance_metrics']['unlearned_retain_acc'],
                    'unlearned_forget_acc': results['performance_metrics']['unlearned_forget_acc'],
                    'gs_retain_acc': results['performance_metrics']['gs_retain_acc'],
                    'zrf_score': results['unlearning_metrics']['zrf_score'],
                    'kl_divergence': results['unlearning_metrics']['kl_divergence'],
                    'forget_effectiveness': results['unlearning_metrics']['forget_effectiveness'],
                    'retain_preservation': results['unlearning_metrics']['retain_preservation'],
                    'unlearning_time': results['timing']['unlearning_time'],
                    'mia_accuracy': results['mia_results'].get('accuracy', 0.5),
                    'timestamp': results['experiment_info']['timestamp']
                }
                
                # æ·»åŠ å¢å¼·è©•ä¼°çš„è©³ç´°æŒ‡æ¨™
                enhanced = results.get('enhanced_metrics', {})
                for metric, value in enhanced.items():
                    if isinstance(value, (int, float)):
                        row[f'enhanced_{metric}'] = value
                
                summary_data.append(row)
        
        if summary_data:
            df = pd.DataFrame(summary_data)
            summary_path = f"{self.exp_dir}/results/layerwise_comprehensive_summary.csv"
            df.to_csv(summary_path, index=False, encoding='utf-8')
            
            self.logger.info(f"è©³ç´°CSVå ±å‘Šå·²ä¿å­˜: {summary_path}")
            return summary_path
        else:
            self.logger.warning("æ²’æœ‰å¯¦é©—çµæœå¯ä»¥ç”ŸæˆCSV")
            return None
    
    def _generate_detailed_report(self, all_results):
        """ç”Ÿæˆè©³ç´°çš„æ–‡å­—å ±å‘Š"""
        report_path = f"{self.exp_dir}/results/layerwise_detailed_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("LayerWise éºå¿˜å¯¦é©—è©³ç´°å ±å‘Š\n")
            f.write("="*80 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¦é©—ç›®éŒ„: {self.exp_dir}\n\n")
            
            # å„éºå¿˜é¡åˆ¥é…ç½®çš„è©³ç´°çµæœ
            for forget_key, strategies in all_results.items():
                f.write(f"{forget_key.upper()} è©³ç´°çµæœ:\n")
                f.write("-" * 50 + "\n")
                
                # çµ±è¨ˆæˆåŠŸå’Œå¤±æ•—
                strategy_success = sum(1 for r in strategies.values() if 'error' not in r)
                strategy_total = len(strategies)
                
                f.write(f"ç­–ç•¥åŸ·è¡Œ: {strategy_success}/{strategy_total} æˆåŠŸ\n\n")
                
                # æŒ‰ZRFåˆ†æ•¸æ’åº
                successful_strategies = []
                failed_strategies = []
                
                for strategy_name, results in strategies.items():
                    if 'error' not in results:
                        zrf = results['unlearning_metrics']['zrf_score']
                        mia_acc = results['mia_results'].get('accuracy', 0.5)
                        successful_strategies.append((strategy_name, zrf, mia_acc, results))
                    else:
                        failed_strategies.append((strategy_name, results['error']))
                
                successful_strategies.sort(key=lambda x: x[1], reverse=True)
                
                # æˆåŠŸçš„ç­–ç•¥æ’å
                if successful_strategies:
                    f.write("æˆåŠŸç­–ç•¥æ’å (æŒ‰ZRFåˆ†æ•¸):\n")
                    for i, (strategy_name, zrf, mia_acc, results) in enumerate(successful_strategies, 1):
                        retain_acc = results['performance_metrics']['unlearned_retain_acc']
                        forget_acc = results['performance_metrics']['unlearned_forget_acc']
                        time_cost = results['timing']['unlearning_time']
                        
                        f.write(f"{i:2d}. {strategy_name:20s} | ZRF: {zrf:8.6f} | ")
                        f.write(f"MIA: {mia_acc:6.4f} | ä¿ç•™: {retain_acc:6.2f}% | ")
                        f.write(f"éºå¿˜: {forget_acc:6.2f}% | æ™‚é–“: {time_cost:6.1f}s\n")
                    f.write("\n")
                
                # å¤±æ•—çš„ç­–ç•¥
                if failed_strategies:
                    f.write("å¤±æ•—ç­–ç•¥:\n")
                    for strategy_name, error in failed_strategies:
                        f.write(f"âœ— {strategy_name}: {error}\n")
                    f.write("\n")
                
                f.write("\n")
        
        self.logger.info(f"è©³ç´°æ–‡å­—å ±å‘Šå·²ä¿å­˜: {report_path}")
        return report_path


def main():
    parser = argparse.ArgumentParser(description='LayerWise éºå¿˜å¯¦é©— - å®Œæ•´ç‰ˆ')
    
    # === åŸºæœ¬è¨­å®š ===
    parser.add_argument("--model_path", type=str, 
                       default="/home/davidhuang/vits-for-small-scale-datasets/checkpoints/ViT_classattn_CIFAR100/BEST_ViT_20250423-0016_lr0.001_bs256_epochs600/best_vit_20250423-0016.pth",
                       help="é è¨“ç·´æ¨¡å‹è·¯å¾‘")
    parser.add_argument("--output_dir", type=str, default="./checkpoints", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--device", type=str, default="cuda", help="è¨ˆç®—è¨­å‚™")
    
    # === éºå¿˜é¡åˆ¥è¨­å®š ===
    parser.add_argument("--forget_class_counts", type=int, nargs='+', 
                       default=[10, 20, 30, 40, 50],
                       help="è¦éºå¿˜çš„é¡åˆ¥æ•¸é‡åˆ—è¡¨")
    parser.add_argument("--seed", type=int, default=42,
                       help="éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¯æ¬¡å¯¦é©—é¡åˆ¥çµ„åˆä¸€è‡´")
    parser.add_argument("--forget_classes", type=str, default=None,
                       help="ç›´æ¥æŒ‡å®šéºå¿˜é¡åˆ¥ (e.g., '20-29' or '20,21,22')ï¼Œæœƒè¦†è“‹forget_class_counts")
    
    # === LayerWise ç­–ç•¥åƒæ•¸ ===
    parser.add_argument("--strategies", type=str, nargs='+',
                       choices=['head_only', 'head_plus_last1', 'head_plus_last2', 
                               'head_plus_last3', 'head_plus_last4', 'head_plus_last5', 
                               'progressive', 'all'],
                       default=['all'],
                       help="è¦æ¸¬è©¦çš„LayerWiseç­–ç•¥")
    
    # === è¨“ç·´åƒæ•¸ ===
    parser.add_argument("--unlearn_epochs", type=int, default=30, 
                       help="LayerWiseéºå¿˜è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--unlearn_lr", type=float, default=5e-5, 
                       help="LayerWiseéºå¿˜å­¸ç¿’ç‡")
    parser.add_argument("--unlearn_lr_min", type=float, default=1e-6, 
                       help="LayerWiseéºå¿˜æœ€å°å­¸ç¿’ç‡")
    # parser.add_argument("--unlearn_lr_scheduler", type=str, 
    #                    choices=['cosine', 'step', 'plateau', 'onecycle'],
    #                    default='cosine', help="LayerWiseéºå¿˜å­¸ç¿’ç‡èª¿åº¦å™¨")
    parser.add_argument("--weight_decay", type=float, default=0.01, 
                       help="æ¬Šé‡è¡°æ¸›")
    parser.add_argument("--batch_size", type=int, default=128, 
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--num_workers", type=int, default=4,
                       help="æ•¸æ“šåŠ è¼‰å™¨å·¥ä½œé€²ç¨‹æ•¸")
    
    # === é»ƒé‡‘æ¨™æº–æ¨¡å‹åƒæ•¸ ===
    parser.add_argument("--gs_epochs", type=int, default=250, 
                       help="é»ƒé‡‘æ¨™æº–æ¨¡å‹è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--gs_lr", type=float, default=1e-3, 
                       help="é»ƒé‡‘æ¨™æº–æ¨¡å‹å­¸ç¿’ç‡")
    parser.add_argument("--gs_lr_min", type=float, default=1e-6, 
                       help="é»ƒé‡‘æ¨™æº–æ¨¡å‹æœ€å°å­¸ç¿’ç‡")
    parser.add_argument("--gs_lr_scheduler", type=str, 
                       choices=['cosine', 'onecycle', 'step'],
                       default='onecycle', help="é»ƒé‡‘æ¨™æº–æ¨¡å‹å­¸ç¿’ç‡èª¿åº¦å™¨")
    parser.add_argument("--gs_weight_decay", type=float, default=0.05, 
                       help="é»ƒé‡‘æ¨™æº–æ¨¡å‹æ¬Šé‡è¡°æ¸›")
    
    # === MIAè©•ä¼°åƒæ•¸ ===
    parser.add_argument("--run_mia", action="store_true", default=True,
                       help="æ˜¯å¦é‹è¡ŒMIAè©•ä¼°")
    parser.add_argument("--no_mia", action="store_false", dest="run_mia",
                       help="è·³éMIAè©•ä¼°")
    parser.add_argument("--mia_epochs", type=int, default=30, 
                       help="MIAæ”»æ“Šæ¨¡å‹è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--mia_lr", type=float, default=1e-3, 
                       help="MIAæ”»æ“Šæ¨¡å‹å­¸ç¿’ç‡")
    parser.add_argument("--mia_use_scheduler", action="store_true", default=True,
                       help="MIAæ˜¯å¦ä½¿ç”¨å­¸ç¿’ç‡èª¿åº¦å™¨")
    
    # === å¢å¼·è©•ä¼°åƒæ•¸ ===
    parser.add_argument("--run_enhanced_eval", action="store_true", default=True,
                       help="æ˜¯å¦é‹è¡Œå¢å¼·è©•ä¼°ï¼ˆcosine similarityç­‰ï¼‰")
    parser.add_argument("--no_enhanced_eval", action="store_false", dest="run_enhanced_eval",
                       help="è·³éå¢å¼·è©•ä¼°")
    
    # === çµæœä¿å­˜åƒæ•¸ ===
    parser.add_argument("--save_models", action="store_true", default=False,
                       help="æ˜¯å¦ä¿å­˜æ‰€æœ‰ä¸­é–“æ¨¡å‹")
    parser.add_argument("--save_detailed_logs", action="store_true", default=True,
                       help="æ˜¯å¦ä¿å­˜è©³ç´°è¨“ç·´æ—¥èªŒ")
    
    # === èª¿è©¦åƒæ•¸ ===
    parser.add_argument("--debug", action="store_true", default=False,
                       help="èª¿è©¦æ¨¡å¼ï¼šä½¿ç”¨è¼ƒå°‘çš„epochså’Œæ•¸æ“š")
    parser.add_argument("--verbose", action="store_true", default=True,
                       help="è©³ç´°è¼¸å‡º")
    
    args = parser.parse_args()
    
    # èª¿è©¦æ¨¡å¼èª¿æ•´
    if args.debug:
        args.unlearn_epochs = min(args.unlearn_epochs, 3)
        args.gs_epochs = min(args.gs_epochs, 5)
        args.mia_epochs = min(args.mia_epochs, 3)
        print("ğŸ› èª¿è©¦æ¨¡å¼å·²å•Ÿç”¨ï¼Œä½¿ç”¨è¼ƒå°‘çš„è¨“ç·´è¼ªæ•¸")
    
    # è™•ç†éºå¿˜é¡åˆ¥é…ç½®
    if args.forget_classes is not None:
        # ç›´æ¥æŒ‡å®šçš„é¡åˆ¥å„ªå…ˆ
        if '-' in args.forget_classes:
            start, end = map(int, args.forget_classes.split('-'))
            forget_classes_configs = [{
                'num_classes': end-start+1, 
                'classes': set(range(start, end+1)), 
                'seed': args.seed
            }]
        else:
            classes = {int(x.strip()) for x in args.forget_classes.split(',') if x.strip()}
            forget_classes_configs = [{
                'num_classes': len(classes), 
                'classes': classes, 
                'seed': args.seed
            }]
    else:
        # ä½¿ç”¨å‹•æ…‹ç”Ÿæˆ
        forget_classes_configs = []
        for num_classes in args.forget_class_counts:
            forget_classes = generate_forget_classes(num_classes, seed=args.seed)
            forget_classes_configs.append({
                'num_classes': num_classes,
                'classes': forget_classes,
                'seed': args.seed
            })
    
    # å‰µå»ºå¯¦é©—å™¨ä¸¦é‹è¡Œ
    experiment = LayerWiseExperiment(args)
    exp_dir, results = experiment.run_all_experiments(forget_classes_configs)
    
    print(f"\næ‰€æœ‰LayerWiseå¯¦é©—å®Œæˆï¼")
    print(f"çµæœä¿å­˜åœ¨: {exp_dir}")


if __name__ == "__main__":
    main()